{"cells":[{"cell_type":"markdown","metadata":{},"source":["Import the necessary Python modules.\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from datetime import date, timedelta\n","import pandas as pd\n","import xgboost as xgb\n","from snowflake.snowpark import functions as F\n","from snowflake.snowpark import types as T\n","from snowflake.ml.utils.connection_params import SnowflakeLoginOptions\n","from snowflake.snowpark import Session"]},{"cell_type":"markdown","metadata":{},"source":["Let's establish a Snowpark session using hextoolkit."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["SnowflakeLoginOptions() is in private preview since 0.2.0. Do not use it in production. \n"]}],"source":["session = Session.builder.configs(SnowflakeLoginOptions()).getOrCreate()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Role: \"SYSADMIN\" | WH: \"COMPUTE_WH\" | DB.SCHEMA: \"STORE_TRAFFIC\".\"TIME_SERIES\"\n"]}],"source":["session.use_database('store_traffic')\n","session.use_schema('TIME_SERIES')\n","print(f\"Role: {session.get_current_role()} | WH: {session.get_current_warehouse()} | DB.SCHEMA: {session.get_fully_qualified_current_schema()}\")"]},{"cell_type":"markdown","metadata":{},"source":["We will start with an existing table that we will want for our Time Series features. The table contains a `DATE` column which is the day the traffic was recorded. We will extract additional date features by joining it to a calendar table we've defined. \n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["store_traffic_info_df = session.table(\"TRAFFIC\")\n","store_calendar_info_df = session.table(\"CALENDAR_INFO_2018\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's preview these tables. "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Unique STORE_IDs: 1000\n","---------------------------------------\n","|\"DATE\"      |\"STORE_ID\"  |\"TRAFFIC\"  |\n","---------------------------------------\n","|2018-01-01  |1           |86         |\n","|2018-01-02  |1           |96         |\n","|2018-01-03  |1           |99         |\n","|2018-01-04  |1           |88         |\n","|2018-01-05  |1           |73         |\n","|2018-01-06  |1           |70         |\n","|2018-01-07  |1           |74         |\n","|2018-01-08  |1           |83         |\n","|2018-01-09  |1           |96         |\n","|2018-01-10  |1           |98         |\n","---------------------------------------\n","\n"]}],"source":["print(f'Number of Unique STORE_IDs: {store_traffic_info_df.select(\"STORE_ID\").distinct().count()}')\n","store_traffic_info_df.show()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------------------------------\n","|\"CALENDAR_DATE\"  |\"WEEK_DAY_NBR\"  |\"MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY_NAME\"  |\n","--------------------------------------------------------------------------------------------------------\n","|2018-01-01       |0               |1              |1               |2018             |New Year's Day  |\n","|2018-01-02       |1               |2              |1               |2018             |NULL            |\n","|2018-01-03       |2               |3              |1               |2018             |NULL            |\n","|2018-01-04       |3               |4              |1               |2018             |NULL            |\n","|2018-01-05       |4               |5              |1               |2018             |NULL            |\n","|2018-01-06       |5               |6              |1               |2018             |NULL            |\n","|2018-01-07       |6               |7              |1               |2018             |NULL            |\n","|2018-01-08       |0               |8              |1               |2018             |NULL            |\n","|2018-01-09       |1               |9              |1               |2018             |NULL            |\n","|2018-01-10       |2               |10             |1               |2018             |NULL            |\n","--------------------------------------------------------------------------------------------------------\n","\n"]}],"source":["store_calendar_info_df.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Engineering"]},{"cell_type":"markdown","metadata":{},"source":["Join the Calendar info table to the traffic table "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------------------------------\n","|\"DATE\"      |\"STORE_ID\"  |\"WEEK_DAY_NBR\"  |\"MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY_NAME\"  |\"TRAFFIC\"  |\n","----------------------------------------------------------------------------------------------------------------------------\n","|2018-01-01  |1           |0               |1              |1               |2018             |New Year's Day  |86         |\n","|2018-01-02  |1           |1               |2              |1               |2018             |No Holiday      |96         |\n","|2018-01-03  |1           |2               |3              |1               |2018             |No Holiday      |99         |\n","|2018-01-04  |1           |3               |4              |1               |2018             |No Holiday      |88         |\n","|2018-01-05  |1           |4               |5              |1               |2018             |No Holiday      |73         |\n","|2018-01-06  |1           |5               |6              |1               |2018             |No Holiday      |70         |\n","|2018-01-07  |1           |6               |7              |1               |2018             |No Holiday      |74         |\n","|2018-01-08  |1           |0               |8              |1               |2018             |No Holiday      |83         |\n","|2018-01-09  |1           |1               |9              |1               |2018             |No Holiday      |96         |\n","|2018-01-10  |1           |2               |10             |1               |2018             |No Holiday      |98         |\n","----------------------------------------------------------------------------------------------------------------------------\n","\n"]}],"source":["past_final = (\n","    store_traffic_info_df.join(\n","        store_calendar_info_df,\n","        (\n","            store_calendar_info_df.col(\"CALENDAR_DATE\")\n","            == store_traffic_info_df.col(\"DATE\")\n","        ),\n","        \"left\",\n","    )\n","    .select(\n","        F.col(\"DATE\"),\n","        \"STORE_ID\",\n","        \"WEEK_DAY_NBR\",\n","        \"MTH_DAY_NBR\",\n","        \"CALENDAR_MTH\",\n","        \"CALENDAR_YEAR\",\n","        \"HOLIDAY_NAME\",\n","        \"TRAFFIC\",\n","    )\n","    .na.fill({\"HOLIDAY_NAME\": \"No Holiday\"})\n",")\n","past_final.show()"]},{"cell_type":"markdown","metadata":{},"source":["Since we will be forecasting out 4 weeks we need 4 weeks of blank calendar data"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------------------------------------------------------\n","|\"CALENDAR_DATE\"  |\"WEEK_DAY_NBR\"  |\"MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY_NAME\"  |\n","--------------------------------------------------------------------------------------------------------\n","|2024-02-27       |1               |27             |2               |2024             |NULL            |\n","|2024-02-28       |2               |28             |2               |2024             |NULL            |\n","|2024-02-29       |3               |29             |2               |2024             |NULL            |\n","|2024-03-01       |4               |1              |3               |2024             |NULL            |\n","|2024-03-02       |5               |2              |3               |2024             |NULL            |\n","|2024-03-03       |6               |3              |3               |2024             |NULL            |\n","|2024-03-04       |0               |4              |3               |2024             |NULL            |\n","|2024-03-05       |1               |5              |3               |2024             |NULL            |\n","|2024-03-06       |2               |6              |3               |2024             |NULL            |\n","|2024-03-07       |3               |7              |3               |2024             |NULL            |\n","--------------------------------------------------------------------------------------------------------\n","\n"]}],"source":["future_cal = (\n","    session.table(\"store_traffic.time_series.CALENDAR_INFO_2018\")\n","    .select(\n","        \"CALENDAR_DATE\",\n","        \"WEEK_DAY_NBR\",\n","        \"MTH_DAY_NBR\",\n","        \"CALENDAR_MTH\",\n","        \"CALENDAR_YEAR\",\n","        \"HOLIDAY_NAME\",\n","    )\n","    .filter(\n","        (F.col(\"CALENDAR_DATE\") >= F.current_date())\n","        & (F.col(\"CALENDAR_DATE\") <= F.current_date() + 28)\n","    )\n",")\n","\n","future_cal.show()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["df_date = session.range(32).select(F.dateadd(\"DAY\", \"ID\", F.current_date()).as_(\"DATE\"))\n","\n","df_date = df_date.select(F.to_date(df_date[\"DATE\"]).as_(\"DATE\"))\n","\n","## Cross join to make sure each store gets a value for the next 4 weeks\n","df_store = (\n","    session.table(\"store_traffic.time_series.traffic\")\n","    .select(F.col(\"STORE_ID\").cast(\"string\").alias(\"STORE_ID\"))\n","    .distinct()\n",")\n","stores = df_date.cross_join(df_store)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------------------\n","|\"DATE\"      |\"STORE_ID\"  |\"WEEK_DAY_NBR\"  |\"MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY_NAME\"  |\n","----------------------------------------------------------------------------------------------------------------\n","|2024-02-27  |1           |1               |27             |2               |2024             |No Holiday      |\n","|2024-02-28  |1           |2               |28             |2               |2024             |No Holiday      |\n","|2024-02-29  |1           |3               |29             |2               |2024             |No Holiday      |\n","|2024-03-01  |1           |4               |1              |3               |2024             |No Holiday      |\n","|2024-03-02  |1           |5               |2              |3               |2024             |No Holiday      |\n","|2024-03-03  |1           |6               |3              |3               |2024             |No Holiday      |\n","|2024-03-04  |1           |0               |4              |3               |2024             |No Holiday      |\n","|2024-03-05  |1           |1               |5              |3               |2024             |No Holiday      |\n","|2024-03-06  |1           |2               |6              |3               |2024             |No Holiday      |\n","|2024-03-07  |1           |3               |7              |3               |2024             |No Holiday      |\n","----------------------------------------------------------------------------------------------------------------\n","\n"]}],"source":["future_cal = future_cal.na.fill({\"HOLIDAY_NAME\": \"No Holiday\"})\n","\n","## Join store info and calendar data\n","future_df = stores.join(\n","    future_cal, stores.col(\"DATE\") == future_cal.col(\"CALENDAR_DATE\"), \"right\"\n",")\n","future_df = future_df.drop(\"CALENDAR_DATE\")\n","future_df.show()"]},{"cell_type":"markdown","metadata":{},"source":["Add a Traffic column pre-filled with zero that will be forecasted once our UDTF executes."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------------------------------------------------------------------\n","|\"DATE\"      |\"STORE_ID\"  |\"WEEK_DAY_NBR\"  |\"MTH_DAY_NBR\"  |\"CALENDAR_MTH\"  |\"CALENDAR_YEAR\"  |\"HOLIDAY_NAME\"  |\"TRAFFIC\"  |\n","----------------------------------------------------------------------------------------------------------------------------\n","|2024-02-27  |1           |1               |27             |2               |2024             |No Holiday      |0          |\n","|2024-02-28  |1           |2               |28             |2               |2024             |No Holiday      |0          |\n","|2024-02-29  |1           |3               |29             |2               |2024             |No Holiday      |0          |\n","|2024-03-01  |1           |4               |1              |3               |2024             |No Holiday      |0          |\n","|2024-03-02  |1           |5               |2              |3               |2024             |No Holiday      |0          |\n","|2024-03-03  |1           |6               |3              |3               |2024             |No Holiday      |0          |\n","|2024-03-04  |1           |0               |4              |3               |2024             |No Holiday      |0          |\n","|2024-03-05  |1           |1               |5              |3               |2024             |No Holiday      |0          |\n","|2024-03-06  |1           |2               |6              |3               |2024             |No Holiday      |0          |\n","|2024-03-07  |1           |3               |7              |3               |2024             |No Holiday      |0          |\n","----------------------------------------------------------------------------------------------------------------------------\n","\n"]}],"source":["future_df = future_df.with_column(\"TRAFFIC\", F.lit(0))\n","\n","future_df = future_df.select(\n","    \"DATE\",\n","    \"STORE_ID\",\n","    \"WEEK_DAY_NBR\",\n","    \"MTH_DAY_NBR\",\n","    \"CALENDAR_MTH\",\n","    \"CALENDAR_YEAR\",\n","    \"HOLIDAY_NAME\",\n","    \"TRAFFIC\",\n",")\n","future_df.show()"]},{"cell_type":"markdown","metadata":{},"source":["Union the historical and future tables together and write back to a Snowflake table."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["unionDF = past_final.union(future_df)\n","\n","unionDF.write.saveAsTable('FEATURES_TRAFFIC', mode='overwrite', create_temp_table=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Creating the User Defined Table Function for multi-node parallelized model training"]},{"cell_type":"markdown","metadata":{},"source":["Create the stage, output schema and UDTF for training and forecasting."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["[Row(status='PYMODELS already exists, statement succeeded.')]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Add stage for UDFs and Stored Procs\n","session.sql(\n","    \"\"\"\n","create stage if not exists pymodels\n","\"\"\"\n",").collect()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["schema = T.StructType([\n","    T.StructField(\"DATE1\", T.DateType()),\n","    T.StructField(\"TRAFFIC_FORECAST\", T.IntegerType())  \n","])\n","\n","@F.udtf(output_schema = schema,\n","     input_types = [T.DateType(), T.IntegerType(), T.StringType(), T.StringType(), T.StringType(), T.StringType()],\n","     name = \"store_traffic_forecast\", is_permanent=True, stage_location=\"@pymodels\", session=session,\n","     packages=[\"pandas\",\"xgboost\"], replace=True)\n","\n","class forecast:\n","    def __init__(self):\n","        self.DATE=[]\n","        self.DAYOFWEEK=[]\n","        self.MONTH=[]\n","        self.YEAR=[]\n","        self.HOLIDAY_NAME=[]\n","        self.TRAFFIC=[]\n","    \n","    def process(self, DATE, TRAFFIC, DAYOFWEEK, MONTH, YEAR, HOLIDAY_NAME):\n","        self.DATE.append(DATE)\n","        self.TRAFFIC.append(TRAFFIC)\n","        self.DAYOFWEEK.append(DAYOFWEEK)\n","        self.MONTH.append(MONTH)\n","        self.YEAR.append(YEAR)\n","        self.HOLIDAY_NAME.append(HOLIDAY_NAME)\n","    \n","    def end_partition(self):\n","        df = pd.DataFrame(zip(self.DATE, \n","                              self.TRAFFIC, \n","                              self.DAYOFWEEK, \n","                              self.MONTH, \n","                              self.YEAR, \n","                              self.HOLIDAY_NAME), \n","                          columns = ['DATE','TRAFFIC','WEEK_DAY_NBR',\n","                                     'CALENDAR_MTH','CALENDAR_YEAR','HOLIDAY_NAME'])\n","        \n","        # set the time column as our index \n","        df2 = df.set_index('DATE') \n","        df2.index = pd.to_datetime(df2.index)\n","\n","         # Converting features to categories for get_dummies\n","        df2['WEEK_DAY_NBR'] = df2['WEEK_DAY_NBR'].astype(\"category\")\n","        df2['CALENDAR_MTH'] = df2['CALENDAR_MTH'].astype(\"category\")\n","        df2['CALENDAR_YEAR'] = df2['CALENDAR_YEAR'].astype(\"category\")\n","        df2['HOLIDAY_NAME'] = df2['HOLIDAY_NAME'].astype(\"category\")\n","\n","        #Use get_dummies for categorical features\n","        final = pd.get_dummies(data=df2, columns=['HOLIDAY_NAME', \n","                                                  'WEEK_DAY_NBR','CALENDAR_MTH','CALENDAR_YEAR'])\n","       \n","        #do the train & forecast split\n","        today = date.today()\n","        last_14 = today - timedelta(days=14)\n","        fourweek = today + timedelta(days = 28)\n","\n","        train = final[(final.index >= pd.to_datetime('01-Jan-2018')) & (final.index < pd.to_datetime(last_14))]\n","        forecast = final[(final.index >= pd.to_datetime(last_14)) & (final.index <=pd.to_datetime(fourweek))]\n","\n","        X_train = train.drop('TRAFFIC', axis = 1)\n","        y_train = train['TRAFFIC']\n","\n","        X_forecast = forecast.drop('TRAFFIC', axis = 1)\n","        \n","        #Use XGBoost regressor model\n","        model = xgb.XGBRegressor(n_estimators=200,n_jobs=1)\n","        model.fit(X_train, y_train,\n","                verbose=False) \n","        \n","        forecast['PREDICTION'] = model.predict(X_forecast)\n","\n","        forecast['DATE'] = forecast.index\n","        forecast = forecast[[\"DATE\",\"PREDICTION\"]]\n","        forecast = forecast.sort_index()\n","        forecast.loc[forecast['PREDICTION'] < 0,'PREDICTION']=0\n","        \n","        # output prediction\n","        for idx, row in forecast.iterrows():\n","            DATE = row['DATE']\n","            PREDICTION = row['PREDICTION']\n","            yield DATE, PREDICTION"]},{"cell_type":"markdown","metadata":{},"source":["Create the query to call to the UDTF and partition by Store ID"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["store_forecast_test = F.table_function(\n","    \"store_traffic.time_series.store_traffic_forecast\"\n",")\n","\n","df = session.table('FEATURES_TRAFFIC')\n","\n","forecast = df.select(\n","    df[\"STORE_ID\"],\n","    (\n","        store_forecast_test(\n","            df[\"DATE\"],\n","            df[\"TRAFFIC\"],\n","            df[\"WEEK_DAY_NBR\"],\n","            df[\"CALENDAR_MTH\"],\n","            df[\"CALENDAR_YEAR\"],\n","            df[\"HOLIDAY_NAME\"],\n","        ).over(partition_by=df[\"STORE_ID\"])\n","    ),\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Write the output to a table esentially calling the UDTF, training and forecasting for the next 4 weeks.  This cell will actually execute the UDTF."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["forecast.with_column_renamed(\"DATE1\", \"DATE\").write.save_as_table(\n","    \"FORECAST\", mode=\"overwrite\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Join forecast to the Actual and visualize the results"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["traffic = session.table(\"FEATURES_TRAFFIC\")\n","forecast = session.table(\"FORECAST\")\n","\n","act_vs_pred = (\n","    traffic.join(\n","        forecast,\n","        (traffic.col(\"DATE\") == forecast.col(\"DATE\"))\n","        & (traffic.col(\"STORE_ID\") == forecast.col(\"STORE_ID\")),\n","    )\n","    .select(\n","        F.cast(traffic.col(\"STORE_ID\"), T.IntegerType()).alias(\"STORE_ID\"),\n","        traffic.col(\"DATE\").alias(\"DATE\"),\n","        F.cast(\n","            F.when(traffic.col(\"DATE\") >= F.current_date(), F.lit(None)).otherwise(\n","                traffic.col(\"TRAFFIC\")\n","            ),\n","            T.IntegerType(),\n","        ).alias(\"ACTUAL\"),\n","        forecast.col(\"TRAFFIC_FORECAST\").alias(\"FORECAST\"),\n","    )\n","    .filter(traffic.col(\"DATE\") > F.current_date() - 15)\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------------------------------------------\n","|\"STORE_ID\"  |\"DATE\"      |\"ACTUAL\"  |\"FORECAST\"  |\n","---------------------------------------------------\n","|1           |2024-02-16  |123       |120         |\n","|1           |2024-02-24  |109       |111         |\n","|1           |2024-02-25  |116       |115         |\n","---------------------------------------------------\n","\n"]}],"source":["act_vs_pred.show(3)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["act_vs_pred.write.saveAsTable('actual_vs_forecast', mode='overwrite', create_temp_table=False)\n","act_v_pred = session.table('actual_vs_forecast')"]},{"cell_type":"markdown","metadata":{},"source":["____"]},{"cell_type":"markdown","metadata":{},"source":["# Vectorized UDTF"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Function that goes inside the UDTF\n","\n","def forecast_function(df:pd.DataFrame) -> pd.DataFrame:\n","    # set the time column as our index \n","    df2 = df.set_index('DATE') \n","    df2.index = pd.to_datetime(df2.index)\n","\n","    # Converting features to categories for get_dummies\n","    df2['WEEK_DAY_NBR'] = df2['WEEK_DAY_NBR'].astype(\"category\")\n","    df2['CALENDAR_MTH'] = df2['CALENDAR_MTH'].astype(\"category\")\n","    df2['CALENDAR_YEAR'] = df2['CALENDAR_YEAR'].astype(\"category\")\n","    df2['HOLIDAY_NAME'] = df2['HOLIDAY_NAME'].astype(\"category\")\n","\n","    #Use get_dummies for categorical features\n","    final = pd.get_dummies(data=df2, columns=['HOLIDAY_NAME', \n","                                                'WEEK_DAY_NBR','CALENDAR_MTH','CALENDAR_YEAR'])\n","    \n","    #do the train & forecast split\n","    today = date.today()\n","    last_14 = today - timedelta(days=14)\n","    fourweek = today + timedelta(days = 28)\n","\n","    train = final[(final.index >= pd.to_datetime('01-Jan-2018')) & (final.index < pd.to_datetime(last_14))]\n","    forecast = final[(final.index >= pd.to_datetime(last_14)) & (final.index <=pd.to_datetime(fourweek))]\n","\n","    X_train = train.drop('TRAFFIC', axis = 1)\n","    y_train = train['TRAFFIC']\n","\n","    X_forecast = forecast.drop('TRAFFIC', axis = 1)\n","    \n","    #Use XGBoost regressor model\n","    model = xgb.XGBRegressor(n_estimators=200,n_jobs=1)\n","    model.fit(X_train, y_train,\n","            verbose=False) \n","    \n","    forecast['PREDICTION'] = model.predict(X_forecast)\n","\n","    forecast['DATE'] = forecast.index\n","    forecast = forecast[[\"DATE\",\"PREDICTION\"]]\n","    forecast = forecast.sort_index()\n","    forecast.loc[forecast['PREDICTION'] < 0,'PREDICTION']=0\n","\n","    return forecast"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["input_df = session.table('FEATURES_TRAFFIC').select([\"STORE_ID\", \"DATE\", \"TRAFFIC\", \"WEEK_DAY_NBR\", \"CALENDAR_MTH\", \"CALENDAR_YEAR\", \"HOLIDAY_NAME\"])\n","# input_df = session.table('FEATURES_TRAFFIC').drop(\"MTH_DAY_NBR\")\n","\n","# Obtain input types and output schema\n","input_col_names = input_df.columns\n","input_dtypes = [field.datatype for field in input_df.schema.fields]\n","vect_udtf_input_dtypes = [T.PandasDataFrameType(input_dtypes)]\n","\n","vect_udtf_output_schema = T.PandasDataFrameType(\n","    [T.DateType(), T.IntegerType()], [\"DATE1\", \"TRAFFIC_FORECAST\"]\n",")\n","\n","@F.udtf(output_schema = vect_udtf_output_schema,\n","     input_types = vect_udtf_input_dtypes,\n","     name = \"store_traffic_vect_udtf\", is_permanent=True, stage_location=\"@pymodels\", session=session,\n","     packages=[\"pandas\",\"xgboost\"], replace=True)\n","class anom_detection:\n","    def end_partition(self, df):\n","        \n","        df.columns = input_col_names # NOTE: In Vectorized udtf you have to put the column names back into the df\n","\n","        forecast = forecast_function(df)\n","\n","        yield forecast"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Call the UDTF\n","store_forecast_test = F.table_function(\n","    \"store_traffic.time_series.store_traffic_vect_udtf\"\n",")\n","\n","forecast_vect_udtf = input_df.select(\n","    \"STORE_ID\",\n","    store_forecast_test(\n","            *[F.col(col_nm) for col_nm in input_col_names]\n","        ).over(partition_by=[\"STORE_ID\"], order_by=[\"DATE\"])\n",")\n","\n","# Write to table\n","forecast_vect_udtf.with_column_renamed(\"DATE1\", \"DATE\").write.save_as_table(\n","    \"FORECAST_VECT_UDTF\", mode=\"overwrite\"\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------------------------------\n","|\"STORE_ID\"  |\"DATE\"      |\"TRAFFIC_FORECAST\"  |\n","------------------------------------------------\n","|659         |2024-02-13  |126                 |\n","|659         |2024-02-14  |129                 |\n","|659         |2024-02-15  |119                 |\n","------------------------------------------------\n","\n"]}],"source":["session.table(\"FORECAST_VECT_UDTF\").show(3)"]},{"cell_type":"markdown","metadata":{},"source":["Compare the code for the scalar vs vectorized UDTF:"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# # THIS CELL LETS YOU SEE THE DIFFERENCE BETWEEN DEFINING/REGISTERING SCALAR & VECTORIZED UDTFS\n","\n","\n","# # **************************************************************\n","# # SCALAR UDTF\n","# # **************************************************************\n","\n","# schema = T.StructType([\n","#     T.StructField(\"DATE1\", T.DateType()),\n","#     T.StructField(\"TRAFFIC_FORECAST\", T.IntegerType())  \n","# ])\n","\n","# @F.udtf(output_schema = schema,\n","#      input_types = [T.DateType(), T.IntegerType(), T.StringType(), T.StringType(), T.StringType(), T.StringType()],\n","#      name = \"store_traffic_forecast\", is_permanent=True, stage_location=\"@pymodels\", session=session,\n","#      packages=[\"pandas\",\"xgboost\"], replace=True)\n","\n","# class forecast:\n","#     def __init__(self):\n","#         self.DATE=[]\n","#         self.DAYOFWEEK=[]\n","#         self.MONTH=[]\n","#         self.YEAR=[]\n","#         self.HOLIDAY_NAME=[]\n","#         self.TRAFFIC=[]\n","    \n","#     def process(self, DATE, TRAFFIC, DAYOFWEEK, MONTH, YEAR, HOLIDAY_NAME):\n","#         self.DATE.append(DATE)\n","#         self.TRAFFIC.append(TRAFFIC)\n","#         self.DAYOFWEEK.append(DAYOFWEEK)\n","#         self.MONTH.append(MONTH)\n","#         self.YEAR.append(YEAR)\n","#         self.HOLIDAY_NAME.append(HOLIDAY_NAME)\n","    \n","#     def end_partition(self):\n","#         df = pd.DataFrame(zip(self.DATE, \n","#                               self.TRAFFIC, \n","#                               self.DAYOFWEEK, \n","#                               self.MONTH, \n","#                               self.YEAR, \n","#                               self.HOLIDAY_NAME), \n","#                           columns = ['DATE','TRAFFIC','WEEK_DAY_NBR',\n","#                                      'CALENDAR_MTH','CALENDAR_YEAR','HOLIDAY_NAME'])\n","        \n","#         forecast = forecast_function(df)\n","        \n","#         # output prediction\n","#         for idx, row in forecast.iterrows():\n","#             DATE = row['DATE']\n","#             PREDICTION = row['PREDICTION']\n","#             yield DATE, PREDICTION\n","\n","\n","# # **************************************************************\n","# # VECTORIZED UDTF\n","# # **************************************************************\n","# input_df = session.table('FEATURES_TRAFFIC').drop(\"MTH_DAY_NBR\")\n","\n","# # Obtain input types and output schema\n","# input_col_names = input_df.columns\n","# input_dtypes = [field.datatype for field in input_df.schema.fields]\n","# vect_udtf_input_dtypes = [T.PandasDataFrameType(input_dtypes)]\n","\n","# vect_udtf_output_schema = T.PandasDataFrameType(\n","#     [T.DateType(), T.IntegerType()], [\"DATE1\", \"TRAFFIC_FORECAST\"]\n","# )\n","\n","# @F.udtf(output_schema = vect_udtf_output_schema,\n","#      input_types = vect_udtf_input_dtypes,\n","#      name = \"store_traffic_vect_udtf\", is_permanent=True, stage_location=\"@pymodels\", session=session,\n","#      packages=[\"pandas\",\"xgboost\"], replace=True)\n","# class anom_detection:\n","#     def end_partition(self, df):\n","       \n","#         df.columns = input_col_names  # NOTE: In Vectorized udtf you have to put the column names back into the df\n","\n","#         forecast = forecast_function(df)\n","\n","#         yield forecast"]}],"metadata":{"hex_info":{"author":"Chase Romano","exported_date":"Thu Feb 15 2024 16:49:15 GMT+0000 (Coordinated Universal Time)","project_id":"f6cea503-7498-4f7b-9a8e-e40cd433d869","version":"draft"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.1.0"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":4}
